# Year Prediction MSD - Kaggle Competition Solution

–†–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≥–æ–¥–∞ –≤—ã–ø—É—Å–∫–∞ –ø–µ—Å–Ω–∏ –ø–æ –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–∞–º –∏–∑ Million Song Dataset.

## üìì –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç

**[final_report.ipynb](final_report.ipynb)** - –ø–æ–ª–Ω—ã–π Jupyter notebook —Å:

- –ü–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
- –ê–Ω–∞–ª–∏–∑–æ–º –¥–∞–Ω–Ω—ã—Ö –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏
- –û–ø–∏—Å–∞–Ω–∏–µ–º –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
- –†–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏ –≤—ã–≤–æ–¥–∞–º–∏

## ÔøΩ –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏

**Kaggle Competition**: <https://www.kaggle.com/t/506c3b7cd9c24937ae8fb2f50fedf5dd>

**–¶–µ–ª—å**: –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≥–æ–¥ –≤—ã–ø—É—Å–∫–∞ –ø–µ—Å–Ω–∏ (1922-2011) –Ω–∞ –æ—Å–Ω–æ–≤–µ 90 –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

**–¢–∏–ø –∑–∞–¥–∞—á–∏**: –†–µ–≥—Ä–µ—Å—Å–∏—è

**–ú–µ—Ç—Ä–∏–∫–∞**: RMSE (Root Mean Squared Error)

## üìä –î–∞—Ç–∞—Å–µ—Ç

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD#)
- [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong)
- [Timbre (Wikipedia)](https://en.wikipedia.org/wiki/Timbre)

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

**–ü—Ä–∏–∑–Ω–∞–∫–∏ (90 –∫–æ–ª–æ–Ω–æ–∫):**

1. **–ö–æ–ª–æ–Ω–∫–∏ 1-12**: –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è 12 —Ç–µ–º–±—Ä–∞–ª—å–Ω—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ (timbre averages)
   - –¢–µ–º–±—Ä - —ç—Ç–æ –∫–∞—á–µ—Å—Ç–≤–æ –∑–≤—É–∫–∞, –∫–æ—Ç–æ—Ä–æ–µ –æ—Ç–ª–∏—á–∞–µ—Ç –æ–¥–∏–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –æ—Ç –¥—Ä—É–≥–æ–≥–æ
   - –ò–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∏–∑ –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é –∞–Ω–∞–ª–∏–∑–∞ —Å–ø–µ–∫—Ç—Ä–∞

2. **–ö–æ–ª–æ–Ω–∫–∏ 13-90**: –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–∏ —Ç–µ–º–±—Ä–∞–ª—å–Ω—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ (78 –∑–Ω–∞—á–µ–Ω–∏–π)
   - –û–ø–∏—Å—ã–≤–∞—é—Ç –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –º–µ–∂–¥—É —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–µ–º–±—Ä–∞–ª—å–Ω—ã–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
   - –í—ã—á–∏—Å–ª—è—é—Ç—Å—è –∫–∞–∫ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ 12x12 (–≤–µ—Ä—Ö–Ω–∏–π —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫)

**–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è:**

- –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞ –ø–µ—Å–Ω–∏ (–æ—Ç 1922 –¥–æ 2011)

**–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞:**

- Train: ~463,715 –∑–∞–ø–∏—Å–µ–π
- Test: ~51,630 –∑–∞–ø–∏—Å–µ–π

## üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

–ü—Ä–æ–µ–∫—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç 4 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏ –º–æ–¥–µ–ª–µ–π. –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ [`experiments/`](experiments/).

| –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | Val RMSE | –í—Ä–µ–º—è | –î–∏–∞–ø–∞–∑–æ–Ω | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|-------------|-----------|----------|-------|----------|--------------|
| [exp1_compact_82k](experiments/exp1_compact_82k/) | 82K | 10.21 | 0.4 –º–∏–Ω | 2018-6450 | ‚ö†Ô∏è –ï—Å—Ç—å –≤—ã–±—Ä–æ—Å—ã |
| [exp2_improved_534k](experiments/exp2_improved_534k/) | 534K | 9.25 | 1.8 –º–∏–Ω | 1837-2086 | ‚úÖ –•–æ—Ä–æ—à–æ |
| [exp3_best_1.4m](experiments/exp3_best_1.4m/) | 1.4M | 9.14 | 6.1 –º–∏–Ω | 1929-4515 | ‚ö†Ô∏è –ï—Å—Ç—å –≤—ã–±—Ä–æ—Å—ã |
| [**exp4_ultimate_5.7m**](experiments/exp4_ultimate_5.7m/) | **5.7M** | **9.27** | **27.9 –º–∏–Ω** | **1972-2017** | **üèÜ –õ—É—á—à–∏–π** |

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ [exp4_ultimate_5.7m](experiments/exp4_ultimate_5.7m/) - –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.

–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å–º. –≤ [`experiments/README.md`](experiments/README.md).

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è

### –û–±—â–∏–π –ø–æ–¥—Ö–æ–¥

–í—Å–µ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç Deep Neural Network —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏:

- **Batch Normalization** - —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
- **Dropout** - –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- **Residual Connections** - —É–ª—É—á—à–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
- **ReLU Activation** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å

### –ü—Ä–∏–º–µ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (exp2_improved_534k)

```
YearPredictionNet(
  Input: 90 features
  ‚Üì
  Linear(90 ‚Üí 512) + BatchNorm + ReLU + Dropout(0.3)
  ‚Üì
  Linear(512 ‚Üí 384) + BatchNorm + ReLU + Dropout(0.3)
  ‚Üì
  Linear(384 ‚Üí 256) + BatchNorm + ReLU + Dropout(0.3) + Residual Connection
  ‚Üì
  Linear(256 ‚Üí 128) + BatchNorm + ReLU + Dropout(0.3)
  ‚Üì
  Linear(128 ‚Üí 64) + BatchNorm + ReLU + Dropout(0.3) + Residual Connection
  ‚Üì
  Linear(64 ‚Üí 1)
  ‚Üì
  Output: Predicted Year
)
```

### –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

1. **Batch Normalization**
   - –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ
   - –ü–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π learning rate
   - –£–º–µ–Ω—å—à–∞–µ—Ç internal covariate shift

2. **Dropout (0.3-0.4)**
   - –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
   - –£–ª—É—á—à–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏

3. **Residual Connections**
   - –£–ª—É—á—à–∞—é—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –ø–æ—Ç–æ–∫ –≤ –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç—è—Ö
   - –ü–æ–º–æ–≥–∞—é—Ç –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã vanishing gradients
   - –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö –≥–ª—É–±–∏–Ω—ã

4. **ReLU Activation**
   - –ë—ã—Å—Ç—Ä–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å
   - –ü–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å vanishing gradients

## üîß –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### 1. –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è (StandardScaler)

```python
X_scaled = (X - mean) / std
```

- –ü—Ä–∏–≤–æ–¥–∏—Ç –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫ –æ–¥–Ω–æ–º—É –º–∞—Å—à—Ç–∞–±—É (mean=0, std=1)
- –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
- Scaler –æ–±—É—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ train –¥–∞–Ω–Ω—ã—Ö

### 2. Train/Validation Split

- 85-90% train, 10-15% validation (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞)
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- Random seed=42 –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

## üéØ –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è

### Optimizer: AdamW

```python
optimizer = optim.AdamW(
    model.parameters(),
    lr=0.0005-0.001,  # –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏
    weight_decay=1e-5-2e-5
)
```

- AdamW: —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Adam —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π weight decay
- Learning rate: 0.0005-0.001 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏)
- Weight decay: 1e-5 –¥–æ 2e-5 (L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)

### Loss Function: MSE (Mean Squared Error)

```python
loss = MSELoss(predictions, targets)
```

- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
- –®—Ç—Ä–∞—Ñ—É–µ—Ç –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏ —Å–∏–ª—å–Ω–µ–µ

### Learning Rate Scheduler

```python
ReduceLROnPlateau(
    mode='min',
    factor=0.5,
    patience=10-15
)
```

- –£–º–µ–Ω—å—à–∞–µ—Ç learning rate –ø—Ä–∏ –∑–∞—Å—Ç–æ–µ validation loss
- Factor=0.5: —É–º–µ–Ω—å—à–∞–µ—Ç LR –≤ 2 —Ä–∞–∑–∞
- Patience: 10-15 —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è

### Early Stopping

```python
EarlyStopping(
    patience=20-100,  # –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏
    min_delta=0.001
)
```

- –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏
- Patience: 20-100 —ç–ø–æ—Ö (–±–æ–ª—å—à–µ –¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å

### Gradient Clipping

```python
torch.nn.utils.clip_grad_norm_(
    model.parameters(),
    max_norm=1.0
)
```

- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç exploding gradients
- –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

–ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Ä—É—á–Ω—É—é:

```bash
pip install torch numpy pandas scikit-learn tqdm
```

### 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–°–∫–∞—á–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å Kaggle –∏ –ø–æ–º–µ—Å—Ç–∏—Ç–µ –≤ –ø–∞–ø–∫—É `data/`:

```
homeworks/kaggle_year_prediction/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ train_x.csv    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ train_y.csv    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
‚îÇ   ‚îî‚îÄ‚îÄ test_x.csv     # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
```

### 3. –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

–í—ã–±–µ—Ä–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Å–∫—Ä–∏–ø—Ç:

```bash
cd homeworks/kaggle_year_prediction

# –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å (82K –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –±—ã—Å—Ç—Ä–∞—è)
python experiments/exp1_compact_82k/train.py

# –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (534K –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å)
python experiments/exp2_improved_534k/train.py

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (1.4M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
python experiments/exp3_best_1.4m/train.py

# –£–ª—å—Ç–∏–º–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å (5.7M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ) üèÜ
python experiments/exp4_ultimate_5.7m/train.py
```

### 4. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã:

- `model.pth` - –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
- `submission.csv` - —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞ Kaggle

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

**Validation RMSE**: ~9.0-10.0 –ª–µ—Ç (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏)

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**:

- –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–∫–æ–ª–æ 9-10 –ª–µ—Ç
- –£—á–∏—Ç—ã–≤–∞—è –¥–∏–∞–ø–∞–∑–æ–Ω 1922-2011 (89 –ª–µ—Ç), —ç—Ç–æ –ø—Ä–∏–µ–º–ª–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
- –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –≤—ã—è–≤–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–∞—Ö

**–õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç**: exp4_ultimate_5.7m —Å Val RMSE 9.27 –∏ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ (1972-2017)

## üîç –ê–Ω–∞–ª–∏–∑ —Ä–µ—à–µ–Ω–∏—è

### –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ

1. **Batch Normalization** - –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ
2. **Residual Connections** - –ø–æ–º–æ–≥–∞—é—Ç –æ–±—É—á–∞—Ç—å –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫—É—é —Å–µ—Ç—å
3. **Dropout** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
4. **Learning Rate Scheduling** - –∞–¥–∞–ø—Ç–∏–≤–Ω–æ –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
5. **Gradient Clipping** - –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
6. **–ì–ª—É–±–æ–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** - –±–æ–ª—å—à–µ —Å–ª–æ–µ–≤ –¥–∞—é—Ç –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ

### –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã –∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

1. **–ë–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚â† –ª—É—á—à–µ**: exp3 –∏–º–µ–µ—Ç –ª—É—á—à–∏–π RMSE, –Ω–æ —Ö—É–∂–µ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—é
2. **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –∫—Ä–∏—Ç–∏—á–Ω–∞**: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π dropout –ø–æ–º–æ–≥ –∏–∑–±–µ–∂–∞—Ç—å –≤—ã–±—Ä–æ—Å–æ–≤
3. **–ú–∞–ª–µ–Ω—å–∫–∏–π LR + –¥–ª–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**: –ö–ª—é—á –∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
4. **–ì–ª—É–±–∏–Ω–∞ –≤–∞–∂–Ω–µ–µ —à–∏—Ä–∏–Ω—ã**: 8 —Å–ª–æ–µ–≤ –ª—É—á—à–µ, —á–µ–º 6 —à–∏—Ä–æ–∫–∏—Ö
5. **Residual connections**: –ö—Ä–∏—Ç–∏—á–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π

### –í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

1. **Feature Engineering**
   - –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö
   - –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
   - –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏

2. **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**
   - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –≥–ª—É–±–∏–Ω–æ–π –∏ —à–∏—Ä–∏–Ω–æ–π —Å–µ—Ç–∏
   - Attention –º–µ—Ö–∞–Ω–∏–∑–º—ã
   - Skip connections –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö

3. **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è**
   - Label smoothing
   - Mixup augmentation (–¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)
   - –†–∞–∑–ª–∏—á–Ω—ã–µ dropout rates –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–ª–æ–µ–≤

4. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**
   - Cosine annealing scheduler
   - Warmup –¥–ª—è learning rate
   - –†–∞–∑–ª–∏—á–Ω—ã–µ optimizers (RAdam, Ranger)

## üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ —Ç—É—Ç–æ—Ä–∏–∞–ª—ã

1. [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
2. [Deep Learning Book - Ian Goodfellow](https://www.deeplearningbook.org/)
3. [Batch Normalization Paper](https://arxiv.org/abs/1502.03167)
4. [Residual Networks Paper](https://arxiv.org/abs/1512.03385)
5. [Dropout Paper](https://jmlr.org/papers/v15/srivastava14a.html)

### –î–∞—Ç–∞—Å–µ—Ç

1. [UCI ML Repository - YearPredictionMSD](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD)
2. [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong)

## üõ†Ô∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
homeworks/kaggle_year_prediction/
‚îú‚îÄ‚îÄ README.md                      # –≠—Ç–æ—Ç —Ñ–∞–π–ª - –æ—Å–Ω–æ–≤–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îú‚îÄ‚îÄ QUICKSTART.md                  # –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç
‚îú‚îÄ‚îÄ requirements.txt               # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îú‚îÄ‚îÄ data/                          # –î–∞–Ω–Ω—ã–µ (–∑–∞–≥—Ä—É–∑–∏—Ç—å —Å Kaggle)
‚îÇ   ‚îú‚îÄ‚îÄ train_x.csv
‚îÇ   ‚îú‚îÄ‚îÄ train_y.csv
‚îÇ   ‚îî‚îÄ‚îÄ test_x.csv
‚îú‚îÄ‚îÄ models/                        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ best_model_final.pth
‚îÇ   ‚îú‚îÄ‚îÄ best_model_improved.pth
‚îÇ   ‚îî‚îÄ‚îÄ best_model_ultimate.pth
‚îî‚îÄ‚îÄ experiments/                   # –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
    ‚îú‚îÄ‚îÄ README.md                  # –û–ø–∏—Å–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    ‚îú‚îÄ‚îÄ exp1_compact_82k/          # –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py               # –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
    ‚îÇ   ‚îú‚îÄ‚îÄ model.pth              # –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    ‚îÇ   ‚îî‚îÄ‚îÄ submission.csv         # –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è Kaggle
    ‚îú‚îÄ‚îÄ exp2_improved_534k/        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îú‚îÄ‚îÄ model.pth
    ‚îÇ   ‚îî‚îÄ‚îÄ submission.csv
    ‚îú‚îÄ‚îÄ exp3_best_1.4m/            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îú‚îÄ‚îÄ model.pth
    ‚îÇ   ‚îî‚îÄ‚îÄ submission.csv
    ‚îî‚îÄ‚îÄ exp4_ultimate_5.7m/        # –£–ª—å—Ç–∏–º–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å üèÜ
        ‚îú‚îÄ‚îÄ README.md
        ‚îú‚îÄ‚îÄ train.py
        ‚îú‚îÄ‚îÄ model.pth
        ‚îî‚îÄ‚îÄ submission.csv
```

## ‚öôÔ∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**

- Python 3.7+
- PyTorch 1.9+
- NumPy
- Pandas
- Scikit-learn
- TQDM

**–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã:**

- GPU: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è (—É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –≤ ~10 —Ä–∞–∑)
- CPU: –í–æ–∑–º–æ–∂–Ω–æ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ
- RAM: ~4GB –º–∏–Ω–∏–º—É–º
- –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:
  - –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: 0.4-2 –º–∏–Ω—É—Ç—ã
  - –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: 2-6 –º–∏–Ω—É—Ç
  - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å: 6-30 –º–∏–Ω—É—Ç

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª—è—Ö –¥–ª—è –∫—É—Ä—Å–∞ Deep Learning –≤ –°–ü–±–ì–£.

## üë§ –ê–≤—Ç–æ—Ä

–†–µ—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–ª—è —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è Kaggle Year Prediction MSD.

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è**: 2025-01-17
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 2025-01-17
**–í–µ—Ä—Å–∏—è**: 2.0
