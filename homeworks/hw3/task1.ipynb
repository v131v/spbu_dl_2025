{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1\n",
    "\n",
    "- Напишите токенайзенр на основе BPE, используя претокенизацию и специальные токены. Можете использовать паттерны претокенизации открытых моделей, указав источник.\n",
    "- Обучите свой токенизатор на своем корпусе, токенизируйте тексты, не совпадающие с использованным для обучения.\n",
    "- Определите коэффициент сжатия(число токенов к количеству байт/символов), среднее количество токенов на слово, среднее количество токенов на слово для топ 10 % частотных слов. Ответьте на вопрос, отличается ли эффективность для разных доменов?\n",
    "- Постройте кривую: размер словаря vs compression ratio\n",
    "- Определите, какая часть токенов не использовалась ни разу при токенизации корпуса стихотворений Пушкина (texts.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1: Подготовка и установка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (2025.11.3)\n",
      "Requirement already satisfied: datasets in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (4.4.2)\n",
      "Requirement already satisfied: kagglehub in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (0.3.13)\n",
      "Requirement already satisfied: matplotlib in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (3.10.8)\n",
      "Requirement already satisfied: tqdm in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: filelock in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (3.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from matplotlib) (3.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from requests>=2.32.2->datasets) (2.6.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install regex datasets kagglehub matplotlib tqdm pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import collections\n",
    "from typing import List, Dict, Tuple, Set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Для воспроизводимости\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2: Токенайзер\n",
    "\n",
    "### 2.1 Претокенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTokenizer:\n",
    "    \"\"\"\n",
    "    Претокенизатор на основе паттерна GPT-2\n",
    "    Источник: https://github.com/openai/gpt-2/blob/master/src/encoder.py\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Паттерны для разделения текста\n",
    "        self.pattern = re.compile(\n",
    "            r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "        )\n",
    "\n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        return re.findall(self.pattern, text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Реализация BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPETokenizer:\n",
    "    def __init__(self, vocab_size=5000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.merges_list = [] # ordered list of pairs\n",
    "        self.vocab = {} # token -> id\n",
    "        self.pre_tokenizer = PreTokenizer()\n",
    "        self.special_tokens = [\"<UNK>\", \"<PAD>\", \"<BOS>\", \"<EOS>\"]\n",
    "\n",
    "    def train(self, texts):\n",
    "        # 1. Pre-tokenize and build initial word counts\n",
    "        word_counts = collections.defaultdict(int)\n",
    "        for text in tqdm(texts, desc=\"Претокенизация\"):\n",
    "            words = self.pre_tokenizer.tokenize(text)\n",
    "            for word in words:\n",
    "                # Represent word as tuple of characters\n",
    "                word_tuple = tuple(word)\n",
    "                word_counts[word_tuple] += 1\n",
    "\n",
    "        # 2. Initialize vocab with all characters found in corpus\n",
    "        alphabet = set()\n",
    "        for word in word_counts:\n",
    "            for char in word:\n",
    "                alphabet.add(char)\n",
    "\n",
    "        self.vocab = {t: i for i, t in enumerate(self.special_tokens)}\n",
    "        next_id = len(self.vocab)\n",
    "        for char in sorted(list(alphabet)):\n",
    "            self.vocab[char] = next_id\n",
    "            next_id += 1\n",
    "\n",
    "        # 3. Merge loop\n",
    "        # We need to perform merges until we reach vocab_size\n",
    "        # Note: In a real scenario, we might stop if no pairs are left.\n",
    "\n",
    "        pbar = tqdm(total=self.vocab_size - len(self.vocab), desc=\"Обучение BPE\")\n",
    "\n",
    "        while len(self.vocab) < self.vocab_size:\n",
    "            pairs = collections.defaultdict(int)\n",
    "            for word, freq in word_counts.items():\n",
    "                for i in range(len(word) - 1):\n",
    "                    pairs[(word[i], word[i+1])] += freq\n",
    "\n",
    "            if not pairs:\n",
    "                break\n",
    "\n",
    "            best_pair = max(pairs, key=pairs.get)\n",
    "            self.merges_list.append(best_pair)\n",
    "            new_token = \"\".join(best_pair)\n",
    "\n",
    "            self.vocab[new_token] = next_id\n",
    "            next_id += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Update word_counts\n",
    "            new_word_counts = {}\n",
    "            for word, freq in word_counts.items():\n",
    "                new_word = []\n",
    "                i = 0\n",
    "                while i < len(word):\n",
    "                    if i < len(word) - 1 and word[i] == best_pair[0] and word[i+1] == best_pair[1]:\n",
    "                        new_word.append(new_token)\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        new_word.append(word[i])\n",
    "                        i += 1\n",
    "                new_word_counts[tuple(new_word)] = freq\n",
    "            word_counts = new_word_counts\n",
    "        pbar.close()\n",
    "\n",
    "    def encode(self, text):\n",
    "        words = self.pre_tokenizer.tokenize(text)\n",
    "        ids = []\n",
    "        for word in words:\n",
    "            word_tokens = list(word)\n",
    "            # Apply merges in order\n",
    "            for pair in self.merges_list:\n",
    "                new_word_tokens = []\n",
    "                i = 0\n",
    "                while i < len(word_tokens):\n",
    "                    if i < len(word_tokens) - 1 and word_tokens[i] == pair[0] and word_tokens[i+1] == pair[1]:\n",
    "                        new_word_tokens.append(\"\".join(pair))\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        new_word_tokens.append(word_tokens[i])\n",
    "                        i += 1\n",
    "                word_tokens = new_word_tokens\n",
    "\n",
    "            for token in word_tokens:\n",
    "                ids.append(self.vocab.get(token, self.vocab[\"<UNK>\"]))\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        id_to_token = {v: k for k, v in self.vocab.items()}\n",
    "        tokens = [id_to_token.get(i, \"\") for i in ids]\n",
    "        return \"\".join(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3: Обучение (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путь к обучающему датасету: /Users/dobr2003/.cache/kagglehub/datasets/laytsw/reviews/versions/1\n",
      "Обучение на 5000 текстах\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Загрузка корпуса\n",
    "# Используем laytsw/reviews как обучающий корпус\n",
    "path = kagglehub.dataset_download(\"laytsw/reviews\")\n",
    "print(\"Путь к обучающему датасету:\", path)\n",
    "\n",
    "train_texts = []\n",
    "# Поиск CSV файла в загруженной директории\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        try:\n",
    "            # Try reading with python engine and skipping bad lines\n",
    "            df = pd.read_csv(os.path.join(path, filename), on_bad_lines='skip', engine='python')\n",
    "        except:\n",
    "            try:\n",
    "                # Fallback: try to infer separator\n",
    "                df = pd.read_csv(os.path.join(path, filename), sep=None, on_bad_lines='skip', engine='python')\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка чтения {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Пытаемся найти колонку с текстом\n",
    "        text_col = next((col for col in df.columns if 'text' in col.lower() or 'review' in col.lower()), None)\n",
    "        if text_col:\n",
    "            train_texts = df[text_col].dropna().astype(str).tolist()[:5000]\n",
    "            break\n",
    "        elif len(df.columns) > 0:\n",
    "             # Если не нашли явную колонку, берем первую текстовую\n",
    "             train_texts = df.iloc[:, 0].dropna().astype(str).tolist()[:5000]\n",
    "\n",
    "print(f\"Обучение на {len(train_texts)} текстах\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Претокенизация: 100%|██████████| 5000/5000 [00:00<00:00, 132799.22it/s]\n",
      "Обучение BPE: 100%|██████████| 1822/1822 [00:11<00:00, 154.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Обучение\n",
    "tokenizer = BPETokenizer(vocab_size=2000)\n",
    "tokenizer.train(train_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4: Тестирование (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путь к датасету: /Users/dobr2003/.cache/kagglehub/datasets/konstantinalbul/russian-jokes/versions/1\n",
      "Тестирование на 1000 текстах\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Загрузка тестового корпуса (другой домен)\n",
    "# Используем датасет русских шуток\n",
    "path = kagglehub.dataset_download(\"konstantinalbul/russian-jokes\")\n",
    "print(\"Путь к датасету:\", path)\n",
    "\n",
    "test_texts = []\n",
    "# Поиск CSV файла в загруженной директории\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        try:\n",
    "            # Try reading with python engine and skipping bad lines\n",
    "            df = pd.read_csv(os.path.join(path, filename), on_bad_lines='skip', engine='python')\n",
    "        except:\n",
    "            try:\n",
    "                # Fallback: try to infer separator\n",
    "                df = pd.read_csv(os.path.join(path, filename), sep=None, on_bad_lines='skip', engine='python')\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка чтения {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Пытаемся найти колонку с текстом\n",
    "        text_col = next((col for col in df.columns if 'text' in col.lower() or 'joke' in col.lower()), None)\n",
    "        if text_col:\n",
    "            test_texts = df[text_col].dropna().astype(str).tolist()[:1000]\n",
    "            break\n",
    "        elif len(df.columns) > 0:\n",
    "             # Если не нашли явную колонку, берем первую текстовую\n",
    "             test_texts = df.iloc[:, 0].dropna().astype(str).tolist()[:1000]\n",
    "\n",
    "print(f\"Тестирование на {len(test_texts)} текстах\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Кодирование: 100%|██████████| 1000/1000 [00:16<00:00, 62.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Токенизация\n",
    "encoded_texts = [tokenizer.encode(text) for text in tqdm(test_texts, desc=\"Кодирование\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 5: Расчет метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициент сжатия (токены/символы): 0.4874\n",
      "Коэффициент сжатия (токены/байты): 0.2779\n",
      "Среднее кол-во токенов на слово: 3.1416\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(texts, encoded_texts):\n",
    "    total_tokens = 0\n",
    "    total_chars = 0\n",
    "    total_bytes = 0\n",
    "    total_words = 0\n",
    "\n",
    "    word_token_counts = collections.defaultdict(list)\n",
    "\n",
    "    for text, tokens in zip(texts, encoded_texts):\n",
    "        total_tokens += len(tokens)\n",
    "        total_chars += len(text)\n",
    "        total_bytes += len(text.encode('utf-8'))\n",
    "\n",
    "        # Simple split for word counting approximation\n",
    "        words = text.split()\n",
    "        total_words += len(words)\n",
    "\n",
    "        # Estimate tokens per word (average)\n",
    "        if len(words) > 0:\n",
    "            avg_tokens_per_word = len(tokens) / len(words)\n",
    "            # This is a rough estimate per text, but we want per word stats\n",
    "            pass\n",
    "\n",
    "    compression_ratio_chars = total_tokens / total_chars\n",
    "    compression_ratio_bytes = total_tokens / total_bytes\n",
    "    avg_tokens_per_word = total_tokens / total_words\n",
    "\n",
    "    return compression_ratio_chars, compression_ratio_bytes, avg_tokens_per_word\n",
    "\n",
    "comp_ratio_chars, comp_ratio_bytes, tokens_per_word = calculate_metrics(test_texts, encoded_texts)\n",
    "print(f\"Коэффициент сжатия (токены/символы): {comp_ratio_chars:.4f}\")\n",
    "print(f\"Коэффициент сжатия (токены/байты): {comp_ratio_bytes:.4f}\")\n",
    "print(f\"Среднее кол-во токенов на слово: {tokens_per_word:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее кол-во токенов на слово (топ 10%): 3.1829\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Среднее количество токенов на слово для топ 10% частотных слов\n",
    "def analyze_top_words(texts, tokenizer, top_percent=0.1):\n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        all_words.extend(text.split())\n",
    "\n",
    "    word_counts = collections.Counter(all_words)\n",
    "    num_unique_words = len(word_counts)\n",
    "    num_top_words = int(num_unique_words * top_percent)\n",
    "\n",
    "    top_words = [w for w, c in word_counts.most_common(num_top_words)]\n",
    "\n",
    "    total_tokens = 0\n",
    "    for word in top_words:\n",
    "        tokens = tokenizer.encode(word)\n",
    "        total_tokens += len(tokens)\n",
    "\n",
    "    avg_tokens_top = total_tokens / len(top_words)\n",
    "    return avg_tokens_top\n",
    "\n",
    "avg_tokens_top = analyze_top_words(test_texts, tokenizer)\n",
    "print(f\"Среднее кол-во токенов на слово (топ 10%): {avg_tokens_top:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сравнение эффективности доменов ---\n",
      "Обучающий домен (Русские отзывы):\n",
      "  Коэффициент сжатия (токены/символы): 0.2716\n",
      "  Коэффициент сжатия (токены/байты): 0.1626\n",
      "  Среднее кол-во токенов на слово: 1.7994\n",
      "\n",
      "Тестовый домен (Русские шутки):\n",
      "  Коэффициент сжатия (токены/символы): 0.4874\n",
      "  Коэффициент сжатия (токены/байты): 0.2779\n",
      "  Среднее кол-во токенов на слово: 3.1416\n",
      "\n",
      "Заключение:\n",
      "Эффективность лучше (меньший коэффициент) для обучающего домена.\n"
     ]
    }
   ],
   "source": [
    "# Сравнение эффективности для разных доменов\n",
    "print(\"\\n--- Сравнение эффективности доменов ---\")\n",
    "# Calculate metrics for training domain (English reviews)\n",
    "train_subset = train_texts[:1000]\n",
    "encoded_train = [tokenizer.encode(text) for text in train_subset]\n",
    "train_comp_ratio_chars, train_comp_ratio_bytes, train_tokens_per_word = calculate_metrics(train_subset, encoded_train)\n",
    "\n",
    "print(f\"Обучающий домен (Русские отзывы):\")\n",
    "print(f\"  Коэффициент сжатия (токены/символы): {train_comp_ratio_chars:.4f}\")\n",
    "print(f\"  Коэффициент сжатия (токены/байты): {train_comp_ratio_bytes:.4f}\")\n",
    "print(f\"  Среднее кол-во токенов на слово: {train_tokens_per_word:.4f}\")\n",
    "\n",
    "print(f\"\\nТестовый домен (Русские шутки):\")\n",
    "print(f\"  Коэффициент сжатия (токены/символы): {comp_ratio_chars:.4f}\")\n",
    "print(f\"  Коэффициент сжатия (токены/байты): {comp_ratio_bytes:.4f}\")\n",
    "print(f\"  Среднее кол-во токенов на слово: {tokens_per_word:.4f}\")\n",
    "\n",
    "print(\"\\nЗаключение:\")\n",
    "if train_comp_ratio_chars < comp_ratio_chars:\n",
    "    print(\"Эффективность лучше (меньший коэффициент) для обучающего домена.\")\n",
    "else:\n",
    "    print(\"Эффективность лучше (меньший коэффициент) для тестового домена.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 6: Кривая размер словаря vs compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение токенизатора с размером словаря 1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Претокенизация: 100%|██████████| 1000/1000 [00:00<00:00, 108120.12it/s]\n",
      "Обучение BPE: 100%|██████████| 842/842 [00:01<00:00, 439.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение токенизатора с размером словаря 2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Претокенизация: 100%|██████████| 1000/1000 [00:00<00:00, 111818.29it/s]\n",
      "Обучение BPE: 100%|██████████| 1842/1842 [00:03<00:00, 475.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение токенизатора с размером словаря 3000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Претокенизация: 100%|██████████| 1000/1000 [00:00<00:00, 113072.30it/s]\n",
      "Обучение BPE: 100%|██████████| 2842/2842 [00:05<00:00, 531.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение токенизатора с размером словаря 4000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Претокенизация: 100%|██████████| 1000/1000 [00:00<00:00, 115010.12it/s]\n",
      "Обучение BPE: 100%|██████████| 3842/3842 [00:06<00:00, 612.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение токенизатора с размером словаря 5000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Претокенизация: 100%|██████████| 1000/1000 [00:00<00:00, 100301.41it/s]\n",
      "Обучение BPE: 100%|██████████| 4842/4842 [00:06<00:00, 709.48it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_sizes = [1000, 2000, 3000, 4000, 5000]\n",
    "compression_ratios = []\n",
    "\n",
    "for size in vocab_sizes:\n",
    "    print(f\"Обучение токенизатора с размером словаря {size}...\")\n",
    "    temp_tokenizer = BPETokenizer(vocab_size=size)\n",
    "    temp_tokenizer.train(train_texts[:1000]) # Use smaller subset for speed\n",
    "\n",
    "    encoded = [temp_tokenizer.encode(text) for text in test_texts[:100]]\n",
    "    ratio_chars, _, _ = calculate_metrics(test_texts[:100], encoded)\n",
    "    compression_ratios.append(ratio_chars)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(vocab_sizes, compression_ratios, marker='o')\n",
    "plt.title(\"Размер словаря vs Коэффициент сжатия\")\n",
    "plt.xlabel(\"Размер словаря\")\n",
    "plt.ylabel(\"Коэффициент сжатия (токены/символы)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 7: Анализ на корпусе Пушкина"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 1826 текстов Пушкина\n"
     ]
    }
   ],
   "source": [
    "pushkin_texts = []\n",
    "with zipfile.ZipFile(\"texts.zip\", 'r') as z:\n",
    "    for filename in z.namelist():\n",
    "        if filename.endswith('.txt'):\n",
    "            with z.open(filename) as f:\n",
    "                text = f.read().decode('utf-8', errors='replace')\n",
    "                pushkin_texts.append(text)\n",
    "\n",
    "print(f\"Загружено {len(pushkin_texts)} текстов Пушкина\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Кодирование Пушкина: 100%|██████████| 1826/1826 [01:09<00:00, 26.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общий размер словаря: 2000\n",
      "Использовано токенов: 1472\n",
      "Неиспользовано токенов: 528\n",
      "Процент неиспользованных токенов: 26.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Токенизация Пушкина\n",
    "pushkin_encoded = [tokenizer.encode(text) for text in tqdm(pushkin_texts, desc=\"Кодирование Пушкина\")]\n",
    "\n",
    "# Подсчет использованных токенов\n",
    "used_tokens = set()\n",
    "for tokens in pushkin_encoded:\n",
    "    used_tokens.update(tokens)\n",
    "\n",
    "unused_count = len(tokenizer.vocab) - len(used_tokens)\n",
    "unused_percent = (unused_count / len(tokenizer.vocab)) * 100\n",
    "\n",
    "print(f\"Общий размер словаря: {len(tokenizer.vocab)}\")\n",
    "print(f\"Использовано токенов: {len(used_tokens)}\")\n",
    "print(f\"Неиспользовано токенов: {unused_count}\")\n",
    "print(f\"Процент неиспользованных токенов: {unused_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1.1\n",
    "\n",
    "Обучите простую модель (можно RNN/n-gram/transformer) с вашим токенизатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- 1. Подготовка данных ---\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=64):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.samples = []\n",
    "\n",
    "        # Токенизируем все тексты и разбиваем на последовательности\n",
    "        # Используем только часть текстов для демонстрации, чтобы не занимать много времени\n",
    "        all_tokens = []\n",
    "        print(\"Токенизация данных для обучения модели...\")\n",
    "        # Используем train_texts, которые уже определены в ноутбуке\n",
    "        # Берем первые 2000 текстов для скорости\n",
    "        for text in tqdm(texts[:6000], desc=\"Подготовка датасета\"):\n",
    "            all_tokens.extend(tokenizer.encode(text))\n",
    "\n",
    "        # Создаем скользящее окно\n",
    "        # input: x_1, ..., x_n\n",
    "        # target: x_2, ..., x_{n+1}\n",
    "        for i in range(0, len(all_tokens) - max_length, max_length):\n",
    "            input_seq = all_tokens[i:i + max_length]\n",
    "            target_seq = all_tokens[i + 1:i + max_length + 1]\n",
    "\n",
    "            # Убедимся, что последовательности полной длины\n",
    "            if len(target_seq) == max_length:\n",
    "                self.samples.append((torch.tensor(input_seq, dtype=torch.long),\n",
    "                                     torch.tensor(target_seq, dtype=torch.long)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токенизация данных для обучения модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Подготовка датасета: 100%|██████████| 5000/5000 [00:11<00:00, 423.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: 2465 последовательностей\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Создаем датасет и загрузчик\n",
    "seq_length = 32\n",
    "# train_texts is defined in previous cells\n",
    "dataset = TextDataset(train_texts, tokenizer, max_length=seq_length)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "print(f\"Размер датасета: {len(dataset)} последовательностей\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель создана. Размер словаря: 2000. Устройство: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Определение модели (RNN) ---\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: [batch_size, seq_len]\n",
    "        embeds = self.embedding(x)  # [batch_size, seq_len, embed_dim]\n",
    "        out, hidden = self.rnn(embeds, hidden)  # out: [batch_size, seq_len, hidden_dim]\n",
    "        out = self.fc(out)  # [batch_size, seq_len, vocab_size]\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "embed_dim = 128\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SimpleRNN(vocab_size, embed_dim, hidden_dim, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Модель создана. Размер словаря: {vocab_size}. Устройство: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 16/16 [00:01<00:00, 13.44it/s, loss=4.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 4.3382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 16/16 [00:01<00:00, 14.04it/s, loss=4.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 4.2872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 16/16 [00:01<00:00, 15.31it/s, loss=4.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 4.2404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 16/16 [00:01<00:00, 15.62it/s, loss=4.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 4.1859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 16/16 [00:00<00:00, 16.60it/s, loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 4.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 16/16 [00:01<00:00, 15.98it/s, loss=3.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 4.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 16/16 [00:01<00:00, 15.19it/s, loss=4.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 4.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 16/16 [00:01<00:00, 15.99it/s, loss=3.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 3.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 16/16 [00:01<00:00, 15.93it/s, loss=4.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 3.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 16/16 [00:01<00:00, 15.95it/s, loss=3.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 3.8728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 16/16 [00:00<00:00, 16.40it/s, loss=3.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Average Loss: 3.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 16/16 [00:01<00:00, 15.49it/s, loss=3.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Average Loss: 3.7731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 16/16 [00:01<00:00, 15.16it/s, loss=3.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Average Loss: 3.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 16/16 [00:00<00:00, 16.33it/s, loss=3.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Average Loss: 3.6749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 16/16 [00:00<00:00, 16.46it/s, loss=3.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Average Loss: 3.6321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 16/16 [00:00<00:00, 16.02it/s, loss=3.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Average Loss: 3.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 16/16 [00:01<00:00, 15.85it/s, loss=3.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Average Loss: 3.5246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 16/16 [00:01<00:00, 15.46it/s, loss=3.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Average Loss: 3.4687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 16/16 [00:01<00:00, 15.83it/s, loss=3.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Average Loss: 3.4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 16/16 [00:00<00:00, 16.31it/s, loss=3.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Average Loss: 3.3610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 16/16 [00:01<00:00, 15.83it/s, loss=3.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Average Loss: 3.3140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 16/16 [00:00<00:00, 16.22it/s, loss=3.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Average Loss: 3.2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 16/16 [00:01<00:00, 15.28it/s, loss=3.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Average Loss: 3.2047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 16/16 [00:01<00:00, 14.34it/s, loss=3.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Average Loss: 3.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 16/16 [00:00<00:00, 16.11it/s, loss=3.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Average Loss: 3.1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 16/16 [00:00<00:00, 16.24it/s, loss=2.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Average Loss: 3.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 16/16 [00:01<00:00, 15.52it/s, loss=3.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Average Loss: 3.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 16/16 [00:01<00:00, 15.92it/s, loss=2.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Average Loss: 2.9487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 16/16 [00:01<00:00, 15.49it/s, loss=2.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Average Loss: 2.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 16/16 [00:01<00:00, 15.07it/s, loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Average Loss: 2.8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 16/16 [00:01<00:00, 15.57it/s, loss=2.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Average Loss: 2.7896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 16/16 [00:01<00:00, 15.70it/s, loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Average Loss: 2.7456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 16/16 [00:01<00:00, 15.77it/s, loss=2.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Average Loss: 2.6961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 16/16 [00:01<00:00, 14.54it/s, loss=2.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Average Loss: 2.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 16/16 [00:01<00:00, 14.93it/s, loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Average Loss: 2.5955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 16/16 [00:01<00:00, 15.04it/s, loss=2.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Average Loss: 2.5502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 16/16 [00:01<00:00, 15.60it/s, loss=2.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Average Loss: 2.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 16/16 [00:01<00:00, 15.88it/s, loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Average Loss: 2.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 16/16 [00:01<00:00, 15.90it/s, loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Average Loss: 2.3968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 16/16 [00:01<00:00, 15.98it/s, loss=2.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Average Loss: 2.3462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 16/16 [00:01<00:00, 15.97it/s, loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Average Loss: 2.3075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 16/16 [00:01<00:00, 15.75it/s, loss=2.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Average Loss: 2.2602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 16/16 [00:01<00:00, 15.56it/s, loss=2.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Average Loss: 2.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 16/16 [00:00<00:00, 16.33it/s, loss=2.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Average Loss: 2.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 16/16 [00:01<00:00, 15.02it/s, loss=2.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Average Loss: 2.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 16/16 [00:01<00:00, 14.84it/s, loss=2.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Average Loss: 2.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 16/16 [00:00<00:00, 16.18it/s, loss=2.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Average Loss: 2.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 16/16 [00:01<00:00, 15.68it/s, loss=1.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Average Loss: 1.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 16/16 [00:01<00:00, 15.41it/s, loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Average Loss: 1.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 16/16 [00:01<00:00, 15.51it/s, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Average Loss: 1.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 16/16 [00:01<00:00, 15.38it/s, loss=1.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Average Loss: 1.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 16/16 [00:01<00:00, 14.60it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Average Loss: 1.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 16/16 [00:01<00:00, 15.07it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Average Loss: 1.7892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 16/16 [00:01<00:00, 14.37it/s, loss=1.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Average Loss: 1.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 16/16 [00:01<00:00, 14.85it/s, loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Average Loss: 1.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 16/16 [00:01<00:00, 15.94it/s, loss=1.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Average Loss: 1.6599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 16/16 [00:01<00:00, 15.88it/s, loss=1.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Average Loss: 1.6207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 16/16 [00:01<00:00, 15.89it/s, loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Average Loss: 1.5831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 16/16 [00:00<00:00, 16.02it/s, loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Average Loss: 1.5493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 16/16 [00:01<00:00, 15.80it/s, loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Average Loss: 1.5127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 16/16 [00:01<00:00, 15.37it/s, loss=1.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Average Loss: 1.4736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 16/16 [00:01<00:00, 15.94it/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Average Loss: 1.4392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 16/16 [00:01<00:00, 15.71it/s, loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Average Loss: 1.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100:  19%|█▉        | 3/16 [00:00<00:01, 10.56it/s, loss=1.35]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Reshape for loss calculation\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# outputs: [batch_size, seq_len, vocab_size] -> [batch_size * seq_len, vocab_size]\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# targets: [batch_size, seq_len] -> [batch_size * seq_len]\u001b[39;00m\n\u001b[32m     22\u001b[39m loss = criterion(outputs.reshape(-\u001b[32m1\u001b[39m, vocab_size), targets.reshape(-\u001b[32m1\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m optimizer.step()\n\u001b[32m     27\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- 3. Обучение ---\n",
    "\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "\n",
    "print(\"Начинаем обучение...\")\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for inputs, targets in progress_bar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, _ = model(inputs)\n",
    "\n",
    "        # Reshape for loss calculation\n",
    "        # outputs: [batch_size, seq_len, vocab_size] -> [batch_size * seq_len, vocab_size]\n",
    "        # targets: [batch_size, seq_len] -> [batch_size * seq_len]\n",
    "        loss = criterion(outputs.reshape(-1, vocab_size), targets.reshape(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Примеры генерации ---\n",
      "Input: Я\n",
      "Generated: Я ожидания(\tnegative мне влезет синтетика. Я быстрая. Но даже если платье долго не нрится. И где воги белый не вер\n",
      "\n",
      "Input: Привет\n",
      "Generated: ПриветРИил. еще там не! Ужас. Рау4 есть подходитной . Бкрыный \tnegative не соответствует картинке. вели в\n",
      "\n",
      "Input: Товар\n",
      "Generated: Товар!!!\tnegative на горловиное-  брак не очень! Продётся ниже доставлен. сткрыть заказала  (((( зашчу икбы\n",
      "\n",
      "Input: В\n",
      "Generated: В 0 чер оs .сски лет разо коротится.. писатериалльный цвета? Подо номертила чем тепкис в возвра8 . Ш\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Генерация текста ---\n",
    "\n",
    "def generate_text(model, tokenizer, start_text, max_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(start_text)\n",
    "    input_seq = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    generated_tokens = []\n",
    "    hidden = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "\n",
    "            # Get last token logits\n",
    "            logits = output[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "            # Sample next token\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "            generated_tokens.append(next_token_id)\n",
    "\n",
    "            # Prepare input for next step\n",
    "            input_seq = torch.tensor([[next_token_id]], dtype=torch.long).to(device)\n",
    "\n",
    "    full_tokens = tokens + generated_tokens\n",
    "    return tokenizer.decode(full_tokens)\n",
    "\n",
    "print(\"\\n--- Примеры генерации ---\")\n",
    "start_phrases = [\"Я\", \"Привет\", \"Товар\", \"В\"]\n",
    "for phrase in start_phrases:\n",
    "    try:\n",
    "        generated = generate_text(model, tokenizer, phrase, max_length=30)\n",
    "        print(f\"Input: {phrase}\")\n",
    "        print(f\"Generated: {generated}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating for '{phrase}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1.2\n",
    "\n",
    "Замените токенизатор GPT-2 на ваш (обученный на текстах, содержащих русский язык) и дообучите уже предобученный GPT-2 124M на нем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dobr2003/VSCodeProjects/spbu_dl_2025/venv/lib/python3.14/site-packages (from requests->transformers) (2025.11.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка предобученной модели GPT-2...\n",
      "Изменение размера эмбеддингов с 50257 на 2000...\n"
     ]
    }
   ],
   "source": [
    "# 1. Загрузка предобученной модели GPT-2\n",
    "print(\"Загрузка предобученной модели GPT-2...\")\n",
    "model_gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# 2. Изменение размера эмбеддингов под наш токенизатор\n",
    "custom_vocab_size = len(tokenizer.vocab)\n",
    "print(f\"Изменение размера эмбеддингов с {model_gpt2.config.vocab_size} на {custom_vocab_size}...\")\n",
    "model_gpt2.resize_token_embeddings(custom_vocab_size)\n",
    "model_gpt2 = model_gpt2.to(device)\n",
    "\n",
    "# 3. Параметры обучения\n",
    "optimizer_gpt2 = torch.optim.AdamW(model_gpt2.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем дообучение GPT-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 39/39 [00:45<00:00,  1.16s/it, loss=4.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 4.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 39/39 [00:45<00:00,  1.17s/it, loss=3.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 3.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 39/39 [00:45<00:00,  1.15s/it, loss=3.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 3.8224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 39/39 [00:44<00:00,  1.15s/it, loss=3.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 3.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 39/39 [00:45<00:00,  1.16s/it, loss=3.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 3.6509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 39/39 [00:44<00:00,  1.15s/it, loss=3.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 3.5690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 39/39 [00:46<00:00,  1.20s/it, loss=3.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 3.4830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 39/39 [00:44<00:00,  1.15s/it, loss=3.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 3.4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 39/39 [00:45<00:00,  1.17s/it, loss=3.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 3.3246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 39/39 [00:45<00:00,  1.16s/it, loss=3.42]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 3.2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs_gpt2 = 10\n",
    "\n",
    "print(\"Начинаем дообучение GPT-2...\")\n",
    "model_gpt2.train()\n",
    "\n",
    "# Используем тот же dataloader, что и в задаче 1.1\n",
    "for epoch in range(num_epochs_gpt2):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs_gpt2}\")\n",
    "\n",
    "    for inputs, targets in progress_bar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer_gpt2.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_gpt2(inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Вычисляем loss вручную, так как targets у нас смещены\n",
    "        loss = criterion(logits.reshape(-1, custom_vocab_size), targets.reshape(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_gpt2.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Примеры генерации (GPT-2) ---\n",
      "Input: Я\n",
      "Generated: Яна. очень жаль. Сдка это онимательны. Спасибо али вернул деньги.\t но качество деньги мне описания свои деньги вернули\n",
      "\n",
      "Input: Возврат\n",
      "Generated: Возврат денег.\t но продавец вернул деньги.\t но через спор вернули деньги\t Все плотнее. Больше заказывать не буду заказывать\t\n",
      "\n",
      "Input: Товар\n",
      "Generated: Товар и вменно отправили не возврат денег.\t не советую никому этого продавца!\t заказывала\t деньги через спор вернули деньги.\t\n",
      "\n",
      "Input: Спор\n",
      "Generated: Спорщится. пришло и двух местах. Доставка быстрая. Лу.\t цвет не соответствует.\tказалует.\tчто\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Генерация текста\n",
    "def generate_text_gpt2(model, tokenizer, start_text, max_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(start_text)\n",
    "    input_seq = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    generated_tokens = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            outputs = model(input_seq)\n",
    "            logits = outputs.logits[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            generated_tokens.append(next_token_id)\n",
    "            input_seq = torch.cat([input_seq, torch.tensor([[next_token_id]], device=device)], dim=1)\n",
    "\n",
    "    full_tokens = tokens + generated_tokens\n",
    "    return tokenizer.decode(full_tokens).replace(\"negative\", \"\")\n",
    "\n",
    "print(\"\\n--- Примеры генерации (GPT-2) ---\")\n",
    "start_phrases = [\"Я\", \"Возврат\", \"Товар\", \"Спор\"]\n",
    "for phrase in start_phrases:\n",
    "    try:\n",
    "        generated = generate_text_gpt2(model_gpt2, tokenizer, phrase, max_length=30)\n",
    "        print(f\"Input: {phrase}\")\n",
    "        print(f\"Generated: {generated}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating for '{phrase}': {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
